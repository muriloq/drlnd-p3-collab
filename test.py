""" A script for testing the agent in the multi-agent Tennis environment of Udacity Deep Reinforcement Learning nanodegree (Project 3).
The first two command-line arguments are the saved weights of the actor and critic networks generated by the training script (train.py)
This code is heavily based on the proposed exercise, with small changes for compatibility with the Unity environment, and use in the command-line.
"""

from unityagents import UnityEnvironment
from ddpg_agent import Agent
import numpy as np
import sys 
import torch
from collections import deque
import matplotlib.pyplot as plt
import time 

# Check for model filename argument
actor_file = 'checkpoint_actor.pth'
critic_file = 'checkpoint_critic.pth'
if (len(sys.argv) > 2):
    actor_file = sys.argv[1]
    critic_file = sys.argv[2]
print ("Using models ",actor_file, critic_file)

plt.ion()

env = UnityEnvironment(file_name='Tennis_Windows_x86_64_single/Tennis.exe')

# get the default brain
brain_name = env.brain_names[0]
brain = env.brains[brain_name]

# reset the environment
env_info = env.reset(train_mode=False)[brain_name]

# number of actions and state size
action_size = brain.vector_action_space_size
state = env_info.vector_observations[0]
state_size = len(state)

# Instantiate the agent 
agent = Agent(state_size=state_size, action_size=action_size*2, random_seed=64)

# Load the weights from file
agent.actor_local.load_state_dict(torch.load(actor_file))
agent.critic_local.load_state_dict(torch.load(critic_file))

env_info = env.reset(train_mode=False)[brain_name] # reset the environment
state = env_info.vector_observations[0]            # get the current state
score = 0                                          # initialize the score
while True:
    action = agent.act(state, False)               # Don't add noise during test! 
    env_info = env.step(action)[brain_name]        # send the action to the environment
    next_state = env_info.vector_observations[0]   # get the next state
    reward = env_info.rewards[0]                   # get the reward
    done = env_info.local_done[0]                  # see if episode has finished
    score += reward                                # update the score
    state = next_state                             # roll over the state to next time step
    if done:                                       # exit loop if episode finished
        break
    
print("Score: {}".format(score))
env.close()
